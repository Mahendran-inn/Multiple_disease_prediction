{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d1b53fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data= pd.read_csv(\"indian_liver_patient - indian_liver_patient.csv\")\n",
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18e83f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583 entries, 0 to 582\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Age                         583 non-null    int64  \n",
      " 1   Gender                      583 non-null    object \n",
      " 2   Total_Bilirubin             583 non-null    float64\n",
      " 3   Direct_Bilirubin            583 non-null    float64\n",
      " 4   Alkaline_Phosphotase        583 non-null    int64  \n",
      " 5   Alamine_Aminotransferase    583 non-null    int64  \n",
      " 6   Aspartate_Aminotransferase  583 non-null    int64  \n",
      " 7   Total_Protiens              583 non-null    float64\n",
      " 8   Albumin                     583 non-null    float64\n",
      " 9   Albumin_and_Globulin_Ratio  579 non-null    float64\n",
      " 10  Dataset                     583 non-null    int64  \n",
      "dtypes: float64(5), int64(5), object(1)\n",
      "memory usage: 50.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d789df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Albumin_and_Globulin_Ratio']= df['Albumin_and_Globulin_Ratio'].fillna(df['Albumin_and_Globulin_Ratio'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0afd8eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e8325f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers capped. New shape: (583, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_liver= df.copy()\n",
    "\n",
    "\n",
    "for col in df_liver: \n",
    "    Q1 = df_liver[col].quantile(0.25)\n",
    "    Q3 = df_liver[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    " \n",
    "    df_liver[col] = df_liver[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "print(\"Outliers capped. New shape:\", df_liver.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d11bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_liver.drop(columns=[\"Dataset\",\"Gender\"])\n",
    "y = df_liver[\"Dataset\"].apply(lambda x: 1 if x == 2 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e08b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Total_Bilirubin', 'Direct_Bilirubin', 'Alkaline_Phosphotase',\n",
       "       'Alamine_Aminotransferase', 'Aspartate_Aminotransferase',\n",
       "       'Total_Protiens', 'Albumin', 'Albumin_and_Globulin_Ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f148ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dataset",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "7ecdb7c5-aca6-4802-92b5-7cb918f33051",
       "rows": [
        [
         "0",
         "0"
        ],
        [
         "1",
         "0"
        ],
        [
         "2",
         "0"
        ],
        [
         "3",
         "0"
        ],
        [
         "4",
         "0"
        ],
        [
         "5",
         "0"
        ],
        [
         "6",
         "0"
        ],
        [
         "7",
         "0"
        ],
        [
         "8",
         "1"
        ],
        [
         "9",
         "0"
        ],
        [
         "10",
         "0"
        ],
        [
         "11",
         "0"
        ],
        [
         "12",
         "1"
        ],
        [
         "13",
         "0"
        ],
        [
         "14",
         "0"
        ],
        [
         "15",
         "1"
        ],
        [
         "16",
         "0"
        ],
        [
         "17",
         "1"
        ],
        [
         "18",
         "0"
        ],
        [
         "19",
         "0"
        ],
        [
         "20",
         "0"
        ],
        [
         "21",
         "0"
        ],
        [
         "22",
         "0"
        ],
        [
         "23",
         "0"
        ],
        [
         "24",
         "1"
        ],
        [
         "25",
         "0"
        ],
        [
         "26",
         "0"
        ],
        [
         "27",
         "0"
        ],
        [
         "28",
         "1"
        ],
        [
         "29",
         "1"
        ],
        [
         "30",
         "0"
        ],
        [
         "31",
         "0"
        ],
        [
         "32",
         "1"
        ],
        [
         "33",
         "1"
        ],
        [
         "34",
         "1"
        ],
        [
         "35",
         "0"
        ],
        [
         "36",
         "1"
        ],
        [
         "37",
         "0"
        ],
        [
         "38",
         "0"
        ],
        [
         "39",
         "0"
        ],
        [
         "40",
         "0"
        ],
        [
         "41",
         "1"
        ],
        [
         "42",
         "1"
        ],
        [
         "43",
         "0"
        ],
        [
         "44",
         "1"
        ],
        [
         "45",
         "1"
        ],
        [
         "46",
         "0"
        ],
        [
         "47",
         "0"
        ],
        [
         "48",
         "0"
        ],
        [
         "49",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 583
       }
      },
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "578    1\n",
       "579    0\n",
       "580    0\n",
       "581    0\n",
       "582    1\n",
       "Name: Dataset, Length: 583, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5493bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0f358ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: {0: 416, 1: 167}\n",
      "Imbalance ratio: 2.49\n",
      "Dataset is imbalanced → using F1-score as main metric\n",
      "\n",
      " Model Performance Comparison:\n",
      "                    Model  Accuracy  Precision    Recall        F1\n",
      "1      LogisticRegression  0.743590   0.718477  0.743590  0.724916\n",
      "0  DecisionTreeClassifier  0.709402   0.743090  0.709402  0.721299\n",
      "3  RandomForestClassifier  0.717949   0.702843  0.717949  0.709067\n",
      "2    KNeighborsClassifier  0.692308   0.685578  0.692308  0.688751\n",
      "\n",
      " Best model based on F1: LogisticRegression\n",
      " Best model saved as 'best_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "class_counts = np.bincount(y.astype(int)) \n",
    "imbalance_ratio = max(class_counts) / min(class_counts)\n",
    "\n",
    "print(\"Class counts:\", dict(enumerate(class_counts)))\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "\n",
    "if imbalance_ratio > 1.5:\n",
    "    main_metric = \"F1\"\n",
    "    print(\"Dataset is imbalanced → using F1-score as main metric\")\n",
    "else:\n",
    "    main_metric = \"Accuracy\"\n",
    "    print(\"Dataset is balanced → using Accuracy as main metric\")\n",
    "\n",
    "# Models to test\n",
    "models = {\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=2000),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "trained_models = {}  # Store trained model objects\n",
    "\n",
    "\n",
    "# Train & evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(xtrain, ytrain)\n",
    "    y_pred = model.predict(xtest)\n",
    "\n",
    "    trained_models[name] = model  # Store the trained model\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(ytest, y_pred),\n",
    "        \"Precision\": precision_score(ytest, y_pred, average=\"weighted\"),\n",
    "        \"Recall\": recall_score(ytest, y_pred, average=\"weighted\"),\n",
    "        \"F1\": f1_score(ytest, y_pred, average=\"weighted\")\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Sort by chosen main metric\n",
    "df_results = df_results.sort_values(by=main_metric, ascending=False)\n",
    "print(\"\\n Model Performance Comparison:\")\n",
    "print(df_results)\n",
    "\n",
    "# Best model\n",
    "# Best model\n",
    "best_model_name = df_results.iloc[0][\"Model\"]\n",
    "best_model = trained_models[best_model_name]\n",
    "print(f\"\\n Best model based on {main_metric}: {best_model_name}\")\n",
    "\n",
    "\n",
    "# Save the best model to a pickle file\n",
    "with open(\"best_model_liver.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(f\" Best model saved as 'best_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
